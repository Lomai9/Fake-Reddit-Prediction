{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úîÔ∏è Problem Formulation:\n",
        "**The problem: ‚ùé**\n",
        "\n",
        "build ML model to predict if a specific reddit post is fake news or not, by looking at its title.\n",
        "\n",
        "**What is the input? ‚è©**\n",
        "\n",
        "set of data(includle text column ) which is useful in prediction.\n",
        "\n",
        "**What is the output? ‚è™**\n",
        "\n",
        "predict the probability (0-1, float) if a specific reddit post is real news or fake.\n",
        "\n",
        "**What data mining function is required? ü§î**\n",
        "\n",
        "-the data mining function required to build model is classification and prediction.\n",
        "-the data mining function required to text preprocessing is tokenization and vectorization each text\n",
        "\n",
        "**What could be the challenges? ‚õè**\n",
        "\n",
        "\n",
        "*   Very big data that include 60000 record.\n",
        "\n",
        "*   each record in the text column contains a lot of punctuation, non-English letters, misspellings, and grammatical errors. As a result, we need to select a suitable text cleaning technique by testing each one and selecting the one that produces the best results.\n",
        "\n",
        "*  Build pipeline to dealing with categorical data and build ML model\n",
        "\n",
        "\n",
        "\n",
        "**What is the impact? üòÄ**\n",
        "\n",
        "Since false information on the Internet has caused many social problems due to the rise of the social network and its role in various fields such as politics, this model will help solve such problems.\n",
        "\n",
        "**What is an ideal solution?**‚úä\n",
        "\n",
        "The First trail when using Random forest model and searches for the best hyperparameter combination using random search technique when the TfidfVectorizer() by default `word-level vectorizer.`\n",
        "The Score on Kaggle `(0.85350)` and the roc_acc is `0.99`."
      ],
      "metadata": {
        "id": "fuc4TBY7w3-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimental protocol üíª\n",
        "-Import some modules to dealing with data set\n",
        "\n",
        "-load dataset from CSV file\n",
        "\n",
        "-Data Exploration \n",
        "\n",
        "-preprocessing (Check the data if it's Clean or not and clean it if it's not chean)\n",
        "*   preprocessing text Column with two methods.\n",
        "*   Descriptive analysis\n",
        "\n",
        "-Spilt data into train test spilt (Once the data which lemmatizer and once the other data which stemmer)\n",
        "\n",
        "-A Tunable Pipeline\n",
        "\n",
        "\n",
        "*   TfidfVectorizer (I covered both character-level vectorizer and word-level vectorizer).\n",
        "\n",
        "*   building models (seven trail) (I am using Radom forest, Logistic regression,XGboost, MLP )\n",
        "\n",
        "-creating search spaces. (Using Random search 6 times Validation and last one Cross_Validation).\n",
        "\n",
        "-training each model with no. hyperparameters.\n",
        "\n",
        "(training on data cleaned by lemmatizer and the data whose cleaned by stemmer)\n",
        "-predicting the test data.\n",
        "\n",
        "-Create Submit file and check the score of each model on kaggle."
      ],
      "metadata": {
        "id": "vP8YmIznxfnj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpY5h8jZtGM1"
      },
      "source": [
        "# Import some modules to dealing with data set ‚ñ∂"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loading all relevant modules and setting some options:**"
      ],
      "metadata": {
        "id": "L9Vs3FY_K6_i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9rQmhjiCXDz"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra\n",
        "import matplotlib.pyplot as plt #visualizations \n",
        "import seaborn as sns\n",
        "\n",
        "import holoviews as hv\n",
        "#For dealing with text related tasks, we will be using nltk. The terrific scikit-learn library will be used to handle tasks related to machine learning.\n",
        "import nltk \n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# some seeting for pandas and hvplot\n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18j8IidrtbUY"
      },
      "source": [
        "#load dataset from CSV file ‚è¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVqtACTZtcC-"
      },
      "outputs": [],
      "source": [
        "#read dataset into files \n",
        "train= pd.read_csv('/content/xy_train.csv', sep=\",\", na_values=[\"\"]) #train dataset\n",
        "test= pd.read_csv('/content/x_test.csv', sep=\",\", na_values=[\"\"]) #test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15YLD6vTuM5d"
      },
      "source": [
        "#Data Exploration üîç\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YmY49ETAuPYg",
        "outputId": "d69db479-c5e4-44d0-9ccd-0f32666b2ea5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id  \\\n",
              "0  265723   \n",
              "1  284269   \n",
              "2  207715   \n",
              "3  551106   \n",
              "4    8584   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4  Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e3140c4-3501-46b6-a440-341852b3d8d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e3140c4-3501-46b6-a440-341852b3d8d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e3140c4-3501-46b6-a440-341852b3d8d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e3140c4-3501-46b6-a440-341852b3d8d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#display the train set\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "7o8iAu9quSHd",
        "outputId": "b4986118-e642-4325-c607-b844e9fafb69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                                        text\n",
              "0   0                                                  stargazer \n",
              "1   1                                                        yeah\n",
              "2   2  PD: Phoenix car thief gets instructions from YouTube video"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e25291db-658b-4822-86dd-fdac1281855f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e25291db-658b-4822-86dd-fdac1281855f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e25291db-658b-4822-86dd-fdac1281855f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e25291db-658b-4822-86dd-fdac1281855f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#display the first three row of the test set\n",
        "test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzhlGK-Uuji3",
        "outputId": "c478891c-a980-481e-afa5-180d3a84d4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 3)\n",
            "(59151, 2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The texts are mostly written in English using punctuation and don't include emojis. However, as with any real-life text data, there will be slang, grammatical mistakes, misspellings, etc. "
      ],
      "metadata": {
        "id": "3GYG-EyYNh8h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K6koelxAMok"
      },
      "source": [
        "#Preprocessing üßπ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having consistent and clean data is fundamental for good modeling results. No matter how sophisticated your model the basic principle is: trash in trash out. When dealing with NLP the cleaning and pre processing can differ depending on which model you intend to use. We will use frequency based representation methods for our text. Thus, we usually want to have a pretty thorough manipulation of the input data:"
      ],
      "metadata": {
        "id": "IyF8ej19NwpG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc_AX1NQAGVT",
        "outputId": "58a12cf3-72f8-440f-efd6-8d3f9a68ab33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id       0\n",
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#check the null values (train set)\n",
        "train.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG7mW6sGAcYi",
        "outputId": "9c5d1422-d7b9-49ca-ba5f-d8beb54e5d16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id      0\n",
              "text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#check the null values (test set)\n",
        "test.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F4pvMP3B6q0"
      },
      "source": [
        "# Text Cleaning ‚ò∫"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For dealing with text related tasks, we will be using nltk. The terrific scikit-learn library will be used to handle tasks related to machine learning.\n"
      ],
      "metadata": {
        "id": "FYsEL2BtLTMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHHl4ip4tCx5",
        "outputId": "983a4d2f-ad45-4e4a-9ffb-9ce1787264b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `clean_text` function takes a string input and applies a bunch of manipulations to it (described in the code)."
      ],
      "metadata": {
        "id": "Yk4XEGSiQseR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "def clean_text(text, for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    # match one or more white sepace\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    # match <any num of words>\n",
        "    RE_TAGS = re.compile(r\"<.*?>\")\n",
        "    # match any word with word boundary\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b^[^A-Za-z√Ä-≈æ0-9]+\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        # match any word and any punctuation with word boundary.\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    #remove <any num of words>\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    #remove any word with word boundary\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    #remove one or more white sepace\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    \n",
        "    word_tokens = word_tokenize(text)\n",
        "\n",
        "    return word_tokens"
      ],
      "metadata": {
        "id": "6QCjBALptIig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using two methods for text cleaning ü§î\n",
        "\n",
        "\n",
        "\n",
        "1.   **Stemming** is a process that stems or removes last few characters from a word, often leading to incorrect meanings and spelling.\n",
        "\n",
        "    *   it will stem each text if for_embedding parameter was false.\n",
        "\n",
        "\n",
        "2.   **Lemmatization** considers the context and converts the word to its meaningful base form, which is called Lemma.\n",
        "\n",
        "    *  it will lemmtize each text if for_embedding parameter was false.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XIgMdb8TQyYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `stemmer_clean` function"
      ],
      "metadata": {
        "id": "pUb7PwYzR7zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemmer_clean(text, for_embedding=False):\n",
        "\n",
        "  stemmer = SnowballStemmer(\"english\")\n",
        "  word_tokens = clean_text(text, for_embedding)\n",
        "  '''steps:\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemming'''\n",
        "\n",
        "  if for_embedding:\n",
        "    # no stemming, lowering and punctuation / stop words removal\n",
        "    words_filtered = word_tokens\n",
        "  else:\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    words_filtered = [stemmer.stem(word) for word in words_tokens_lower if word not in stop_words ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean\n"
      ],
      "metadata": {
        "id": "u3Iv0DWhu8AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `lemma_clean` function"
      ],
      "metadata": {
        "id": "EYKtgufASYc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemma_clean(text, for_embedding=False):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  word_tokens = clean_text(text, for_embedding)\n",
        "  ''' steps:\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and lemmatize\n",
        "    '''\n",
        "\n",
        "  if for_embedding:\n",
        "    # no lemmatization, lowering and punctuation / stop words removal\n",
        "    words_filtered = word_tokens\n",
        "  else:\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    words_filtered = [lemmatizer.lemmatize(word) for word in words_tokens_lower if word not in stop_words]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ],
      "metadata": {
        "id": "AdqSiUu9t_RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can improve model performance again by increasing the number of relevant data points.\n",
        "Let's apply this to our data:"
      ],
      "metadata": {
        "id": "lYWTFhC0Sed6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"text_clean\"] = train.loc[train[\"text\"].str.len() > 20, \"text\"]"
      ],
      "metadata": {
        "id": "1ap4o5bPw5F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocessing text Column with two methods\n",
        " "
      ],
      "metadata": {
        "id": "MxA4722ATOvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Lemmatizing\n",
        "2.   Stemming\n",
        "\n"
      ],
      "metadata": {
        "id": "aIpY8de_TYAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean text (train set)\n",
        "#clean text with lemmatizing each word in the text \n",
        "#(lemmatizing will remove any word ending with take in consideration the meaning of the word).\n",
        "train_lemma=train['text_clean'].map(lambda x: lemma_clean(x, for_embedding=False) if isinstance(x, str) else x)\n",
        "#clean text with stemming each word in the text \n",
        "#(stemming will remove any word ending without take in consideration the meaning of the word).\n",
        "train_stem=train['text_clean'].map(lambda x: stemmer_clean(x, for_embedding=False) if isinstance(x, str) else x)"
      ],
      "metadata": {
        "id": "be_sJCCfxjmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean text (test set)\n",
        "#clean text with lemmatizing each word in the text \n",
        "#(lemmatizing will remove any word ending with take in consideration the meaning of the word).\n",
        "test_lemma=test['text'].map(lambda x: lemma_clean(x, for_embedding=False) if isinstance(x, str) else x)\n",
        "#clean text with stemming each word in the text \n",
        "#(stemming will remove any word ending without take in consideration the meaning of the word).\n",
        "test_stem=test['text'].map(lambda x: stemmer_clean(x, for_embedding=False) if isinstance(x, str) else x)"
      ],
      "metadata": {
        "id": "gIJuOZdj2uDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cleaned comments are much more concise because of their original sentence structure and their words have been altered severely. Although the meaning can still be grasped, humans will probably have a harder time understanding these sentences. "
      ],
      "metadata": {
        "id": "-R-Y7Lw4UTWj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbuK1-C0Ijcw"
      },
      "source": [
        "### Descriptive analysis ‚úå\n",
        "\n",
        "Even though we deal with texts, we should still use some descriptive analysis to get a better understanding of the data:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the most frequent words, we can identify additional candidates for our stop word list**"
      ],
      "metadata": {
        "id": "dEYgastSUqfK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_NFJ_m8EX9W",
        "outputId": "f355b370-418e-4dda-be76-66d2c1c65bce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ".            34472\n",
              ")            12466\n",
              "(            12456\n",
              ":             9770\n",
              "'s            9618\n",
              "?             8626\n",
              "``            7381\n",
              "''            7231\n",
              "|             6476\n",
              "!             4930\n",
              "'             3632\n",
              "-             3534\n",
              "n't           3292\n",
              "[             3270\n",
              "]             3260\n",
              "one           3201\n",
              "year          3183\n",
              "new           2989\n",
              "like          2911\n",
              "&             2647\n",
              "man           2584\n",
              "colorized     2404\n",
              "trump         2382\n",
              "people        2266\n",
              "look          2215\n",
              "first         2203\n",
              "say           2148\n",
              "get           2069\n",
              "found         1958\n",
              "poster        1948\n",
              "time          1943\n",
              "woman         1813\n",
              "day           1810\n",
              "war           1791\n",
              "make          1706\n",
              "$             1689\n",
              "life          1681\n",
              "...           1625\n",
              "2             1599\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from bokeh.models import NumeralTickFormatter\n",
        "# Word Frequency of most common words in train_lemma\n",
        "word_freq_lemma = pd.Series(\" \".join(train_lemma).split()).value_counts()\n",
        "word_freq_lemma[1:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "MZxqEbYrKDPg",
        "outputId": "36dc1222-7df9-4fd5-ce97-e9ddca73f37f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                        index  \\\n",
              "0  //external-preview.redd.it/book1b119x1ij9al3zh6tenrxz3llmfcs6l2l7vmmoa.jpg   \n",
              "1                                                                      dayi3a   \n",
              "2                                                                         'el   \n",
              "3                                                                1569779293.0   \n",
              "4                                                                     jormono   \n",
              "5                                                                      219x6l   \n",
              "6                                                                      halper   \n",
              "7                                                                    ginsberg   \n",
              "8                                                                     polemic   \n",
              "9                                                                        110k   \n",
              "\n",
              "   freq  \n",
              "0     1  \n",
              "1     1  \n",
              "2     1  \n",
              "3     1  \n",
              "4     1  \n",
              "5     1  \n",
              "6     1  \n",
              "7     1  \n",
              "8     1  \n",
              "9     1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f137013-15df-4fc4-943a-1e0b8153dca9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>//external-preview.redd.it/book1b119x1ij9al3zh6tenrxz3llmfcs6l2l7vmmoa.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dayi3a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'el</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1569779293.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jormono</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>219x6l</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>halper</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ginsberg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>polemic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>110k</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f137013-15df-4fc4-943a-1e0b8153dca9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f137013-15df-4fc4-943a-1e0b8153dca9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f137013-15df-4fc4-943a-1e0b8153dca9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# list most uncommon words\n",
        "word_freq_lemma[-10:].reset_index(name=\"freq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmTg7XdMiG32",
        "outputId": "3b9c4d9f-9be6-43c1-b310-6f11adeff4c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ".         34472\n",
              ")         12466\n",
              "(         12456\n",
              ":          9770\n",
              "'s         9618\n",
              "?          8626\n",
              "``         7381\n",
              "''         7231\n",
              "|          6476\n",
              "!          4930\n",
              "'          3632\n",
              "-          3534\n",
              "n't        3292\n",
              "[          3270\n",
              "]          3260\n",
              "one        3205\n",
              "year       3187\n",
              "like       3099\n",
              "new        2994\n",
              "look       2844\n",
              "color      2702\n",
              "&          2647\n",
              "get        2608\n",
              "man        2604\n",
              "trump      2388\n",
              "say        2353\n",
              "use        2287\n",
              "peopl      2272\n",
              "first      2209\n",
              "make       2200\n",
              "found      1998\n",
              "time       1961\n",
              "poster     1950\n",
              "day        1812\n",
              "war        1792\n",
              "$          1689\n",
              "...        1625\n",
              "2          1598\n",
              "show       1504\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Word Frequency of most common words in train_stem\n",
        "word_freq_stem = pd.Series(\" \".join(train_stem).split()).value_counts()\n",
        "word_freq_stem[1:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Aoktr99iiTtH",
        "outputId": "1850ca82-2ae8-46eb-d604-15311bb8dbdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         index  freq\n",
              "0    al-sunnah     1\n",
              "1     workship     1\n",
              "2     cbssport     1\n",
              "3        majin     1\n",
              "4          buu     1\n",
              "5          774     1\n",
              "6         r/ot     1\n",
              "7  r/sequelmem     1\n",
              "8      doubter     1\n",
              "9         110k     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6042d6e-ba8b-4cd0-9c04-28659de13553\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>al-sunnah</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>workship</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cbssport</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>majin</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>buu</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>774</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>r/ot</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>r/sequelmem</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>doubter</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>110k</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6042d6e-ba8b-4cd0-9c04-28659de13553')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6042d6e-ba8b-4cd0-9c04-28659de13553 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6042d6e-ba8b-4cd0-9c04-28659de13553');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# list most uncommon words\n",
        "word_freq_stem[-10:].reset_index(name=\"freq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMUnA_7X45lj"
      },
      "source": [
        "#Spilt data into train test spilt üò≤"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lemmatizer**"
      ],
      "metadata": {
        "id": "QMWmY2VRBXjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDfkatjx4_mr"
      },
      "outputs": [],
      "source": [
        "#split train_lemma \n",
        "\n",
        "X1=train_lemma\n",
        "Y=train['label']\n",
        "\n",
        "#Split train_lemma set to a train and a validation set becuase we will use them in search method\n",
        "x_train_lemma, x_val_lemma, y_train_lemma, y_val_lemma = train_test_split(X1, Y, test_size=0.25)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# x_train_lemma (new training set), train_lemma\n",
        "split_index_lemmatized = [-1 if x in x_train_lemma.index else 0 for x in train_lemma.index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemmer**\n"
      ],
      "metadata": {
        "id": "XlHdWF8pCg8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split train_stem \n",
        "\n",
        "X2=train_stem\n",
        "\n",
        "#Split train_stem set to a train and a validation set becuase we will use them in search method\n",
        "x_train_stem, x_val_stem, y_train_stem, y_val_stem = train_test_split(X2, Y, test_size=0.25)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# x_train_stem (new training set), train_stem\n",
        "split_index_stemmed = [-1 if x in x_train_stem.index else 0 for x in train_stem.index]\n"
      ],
      "metadata": {
        "id": "S36FSaKzCdHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Tunable Pipeline ‚ûø\n"
      ],
      "metadata": {
        "id": "-Co6vqS7EjAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First trial "
      ],
      "metadata": {
        "id": "hGzds0_l_J_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.   Feature creation with TfidfVectorizer \n",
        "(Because classification models cannot deal with text data directly, we need to convert our text column to a numeric representation.)\n",
        "( For many applications, `TF-IDF` (term frequency, inverse document frequency) is a good choice. In our case, the `TF` part summarizes how often a word appears in a comment in relation to all words.)\n",
        "\n",
        "    *   TfidfVectorizer by default `word-level vectorizer.`\n",
        "\n",
        "\n",
        "\n",
        "2.   building our model (Random Forest with Random Search (validation))\n",
        "\n"
      ],
      "metadata": {
        "id": "2y8pwfehhDIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**this trial on train_lemma**"
      ],
      "metadata": {
        "id": "ApHIUSK8FeWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting each text the input column to numerical values using TfidfVectorizer \n",
        "# training them using Random Forest classifier.\n",
        "\n",
        "RF_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('TF-IDF', TfidfVectorizer()),\n",
        "        ('RandomForest', RandomForestClassifier())]\n",
        ")\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "predefinedspilt1 = PredefinedSplit(split_index_lemmatized)\n",
        "\n",
        "# define parameter space to test\n",
        "\n",
        "params={\n",
        "    # points to TfidfVectorizer->ngram_range \n",
        "    'TF-IDF__ngram_range':[(1,2),(1,3)],\n",
        "    # points to TfidfVectorizer->Max_df \n",
        "    'TF-IDF__max_df': np.arange(0.3, 0.8),\n",
        "    # points to TfidfVectorizer->Min_df \n",
        "    'TF-IDF__min_df': np.arange(5, 100),\n",
        "    # points to RandomForestClassifier->n_estimators \n",
        "    'RandomForest__n_estimators': [10,25,30,50,100,200],\n",
        "    # points to RandomForestClassifier->max_depth \n",
        "    'RandomForest__max_depth':[2,3,5,10,20],\n",
        "    # points to RandomForestClassifier->min_samples_leaf \n",
        "    'RandomForest__min_samples_leaf': [5,10,20,50,100,200]\n",
        "}\n",
        "\n",
        "# it is quite slow so we do 4 for now\n",
        "\n",
        "#Using Random search with validation set\n",
        "#random search CV (may be good enough and even more generalizable)\n",
        "pipe_clf_RF = RandomizedSearchCV(\n",
        "RF_pipline, params, cv=predefinedspilt1, n_jobs=-1, scoring=\"roc_auc\", n_iter=3)\n",
        "\n",
        "# here we still use X1; but the Radom search model  will use our predefined split internally to determine which sample belongs to the validation set\n",
        "\n",
        "#Fit the model on train_lemma\n",
        "pipe_clf_RF.fit(X1, Y)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JSopEiheEE3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best hyperparameters combinations and roc_auc score for TfidfVectorizer() Random Forest classifier\n",
        "\n",
        "best_params = pipe_clf_RF.best_params_\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "T2UtzN-YLvVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the best hyperparameter combination for `TfidfVectorizer`() and use them with the model to search for best hyperparameters combination for the model.\n"
      ],
      "metadata": {
        "id": "FmAU5v_QbDRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this best hyperparameters for `TfidfVectorizer()`, we can search for optimal hyperparameters for the Random Forest classifier becuase that will improve the classification results:\n",
        "\n"
      ],
      "metadata": {
        "id": "I1UcuvbJbMGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model with best param\n",
        "\n",
        "RF_pipline.set_params(**best_params).fit(X1, Y)\n"
      ],
      "metadata": {
        "id": "owkMBN4qNrRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the roc_auc score of the best params\n",
        "RF_pipline.set_params(**best_params).score(X1,Y)"
      ],
      "metadata": {
        "id": "Y8AI0udI30xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test['id']\n",
        "submission['label'] = RF_pipline.predict_proba(test['text'])[:,1]\n",
        "submission.to_csv('Randomforest.csv', index=False)"
      ],
      "metadata": {
        "id": "YYmJnr17L3cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest with Random Search Get the best Score on Kaggle (0.85350)\n",
        "we can improve it by trying to chance hyperparameter"
      ],
      "metadata": {
        "id": "woTMxrQdv3-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Secound trial\n",
        "*   TfidfVectorizer (character-level)\n",
        "*   building **(XGBoost Classifier with Random Search (validation))**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UuSpZ4s8jmGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**this trial on train_lemma**"
      ],
      "metadata": {
        "id": "A0npv8D3FvZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting each text the input column to numerical values using TfidfVectorizer \n",
        "# training them using XGBoost Classifier.\n",
        "XG_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('TF-IDF', TfidfVectorizer(analyzer=\"char\", max_df=0.2, min_df=10, ngram_range=(1, 3), norm=\"l2\")),\n",
        "        ('xgboost', XGBClassifier(random_state=42,n_jobs=-1,eval_metric='rmse'))]\n",
        ")\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "predefinedspilt2 = PredefinedSplit(split_index_lemmatized)\n",
        "\n",
        "# define parameter space to test\n",
        "\n",
        "params_XG={\n",
        "    # points to TfidfVectorizer->ngram_range \n",
        "    'TF-IDF__ngram_range': [(1, 2), (1, 3), (1,4), (1,5)],\n",
        "    # points to TfidfVectorizer->analyzer \n",
        "    'TF-IDF__analyzer':['char'],\n",
        "    # points to TfidfVectorizer->min_df \n",
        "    'TF-IDF__min_df':np.arange(5, 100),\n",
        "    # points to TfidfVectorizer->max_df \n",
        "    'TF-IDF__max_df':np.arange(0.2, 1.0),\n",
        "    # points to xgboost->n_estimators' \n",
        "    'xgboost__n_estimators': [20, 30, 40], \n",
        "    # points to xgboost->max_depth' \n",
        "    'xgboost__max_depth':[10, 20, 30],\n",
        "    # points to xgboost->booster' \n",
        "    'xgboost__booster':['gbtree','gblinear', 'dart'],\n",
        "    # points to xgboost->learning_rate' \n",
        "    'xgboost__learning_rate':[1.0, 0.1,0.01,0.0001, 1.5],  \n",
        "}\n",
        "\n",
        "# it is quite slow so we do 4 for now\n",
        "#Using Random search with validation set\n",
        "#random search CV (may be good enough and even more generalizable)\n",
        "pipe_clf_XG = RandomizedSearchCV(\n",
        "XG_pipline, params_XG, cv=predefinedspilt2, n_jobs=-1, scoring=\"roc_auc\", n_iter=3)\n",
        "\n",
        "# here we still use X1; but the Radom search model  will use our predefined split internally to determine which sample belongs to the validation set\n",
        "#Fit the model on train_lemma\n",
        "pipe_clf_XG.fit(X1, Y)\n"
      ],
      "metadata": {
        "id": "g9uYmG75fTVm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "a95aabe6-8b78-4765-9445-f0c484487cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:53:41] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[('TF-IDF',\n",
              "                                              TfidfVectorizer(analyzer='char',\n",
              "                                                              max_df=0.2,\n",
              "                                                              min_df=10,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           3))),\n",
              "                                             ('xgboost',\n",
              "                                              XGBClassifier(base_score=None,\n",
              "                                                            booster=None,\n",
              "                                                            callbacks=None,\n",
              "                                                            colsample_bylevel=None,\n",
              "                                                            colsample_bynode=None,\n",
              "                                                            colsample_bytree=None,\n",
              "                                                            early_stopping_rounds=None,\n",
              "                                                            enabl...\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'TF-IDF__ngram_range': [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)],\n",
              "                                        'xgboost__booster': ['gbtree',\n",
              "                                                             'gblinear',\n",
              "                                                             'dart'],\n",
              "                                        'xgboost__learning_rate': [1.0, 0.1,\n",
              "                                                                   0.01, 0.0001,\n",
              "                                                                   1.5],\n",
              "                                        'xgboost__max_depth': [10, 20, 30],\n",
              "                                        'xgboost__n_estimators': [20, 30, 40]},\n",
              "                   scoring='roc_auc')"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                                              TfidfVectorizer(analyzer=&#x27;char&#x27;,\n",
              "                                                              max_df=0.2,\n",
              "                                                              min_df=10,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           3))),\n",
              "                                             (&#x27;xgboost&#x27;,\n",
              "                                              XGBClassifier(base_score=None,\n",
              "                                                            booster=None,\n",
              "                                                            callbacks=None,\n",
              "                                                            colsample_bylevel=None,\n",
              "                                                            colsample_bynode=None,\n",
              "                                                            colsample_bytree=None,\n",
              "                                                            early_stopping_rounds=None,\n",
              "                                                            enabl...\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)],\n",
              "                                        &#x27;xgboost__booster&#x27;: [&#x27;gbtree&#x27;,\n",
              "                                                             &#x27;gblinear&#x27;,\n",
              "                                                             &#x27;dart&#x27;],\n",
              "                                        &#x27;xgboost__learning_rate&#x27;: [1.0, 0.1,\n",
              "                                                                   0.01, 0.0001,\n",
              "                                                                   1.5],\n",
              "                                        &#x27;xgboost__max_depth&#x27;: [10, 20, 30],\n",
              "                                        &#x27;xgboost__n_estimators&#x27;: [20, 30, 40]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                                              TfidfVectorizer(analyzer=&#x27;char&#x27;,\n",
              "                                                              max_df=0.2,\n",
              "                                                              min_df=10,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           3))),\n",
              "                                             (&#x27;xgboost&#x27;,\n",
              "                                              XGBClassifier(base_score=None,\n",
              "                                                            booster=None,\n",
              "                                                            callbacks=None,\n",
              "                                                            colsample_bylevel=None,\n",
              "                                                            colsample_bynode=None,\n",
              "                                                            colsample_bytree=None,\n",
              "                                                            early_stopping_rounds=None,\n",
              "                                                            enabl...\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)],\n",
              "                                        &#x27;xgboost__booster&#x27;: [&#x27;gbtree&#x27;,\n",
              "                                                             &#x27;gblinear&#x27;,\n",
              "                                                             &#x27;dart&#x27;],\n",
              "                                        &#x27;xgboost__learning_rate&#x27;: [1.0, 0.1,\n",
              "                                                                   0.01, 0.0001,\n",
              "                                                                   1.5],\n",
              "                                        &#x27;xgboost__max_depth&#x27;: [10, 20, 30],\n",
              "                                        &#x27;xgboost__n_estimators&#x27;: [20, 30, 40]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=10,\n",
              "                                 ngram_range=(1, 3))),\n",
              "                (&#x27;xgboost&#x27;,\n",
              "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=&#x27;rmse&#x27;,\n",
              "                               feature_types=None, gamma=None, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=None,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=None, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=100,\n",
              "                               n_jobs=-1, num_parallel_tree=None,\n",
              "                               predictor=None, random_state=42, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=10, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
              "              predictor=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best hyperparameters combinations and roc_auc score for TfidfVectorizer() XGBoost Classifier\n",
        "best_params2 = pipe_clf_XG.best_params_\n",
        "print(best_params2)"
      ],
      "metadata": {
        "id": "gGcdeCO40ESX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc3c56a-7a79-47d6-a2f2-2820d9d5a5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'xgboost__n_estimators': 30, 'xgboost__max_depth': 10, 'xgboost__learning_rate': 0.01, 'xgboost__booster': 'gblinear', 'TF-IDF__ngram_range': (1, 3), 'TF-IDF__min_df': 49, 'TF-IDF__max_df': 0.2, 'TF-IDF__analyzer': 'char'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the best hyperparameter combination for `TfidfVectorizer`() and use them with the model to search for best hyperparameters combination for the model.\n"
      ],
      "metadata": {
        "id": "yB6fQDzgwMxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this best hyperparameters for `TfidfVectorizer()`, we can search for optimal hyperparameters for XGBoost Classifier becuase that will improve the classification results:\n",
        "\n"
      ],
      "metadata": {
        "id": "yFhpZhLbwMxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model with best param\n",
        "XG_pipline.set_params(**best_params2).fit(X1, Y)\n"
      ],
      "metadata": {
        "id": "Dxa8Jahd0Xo7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "e5e0f0a6-fc83-4221-b9cd-9ddbecd954a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:53:58] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('TF-IDF',\n",
              "                 TfidfVectorizer(analyzer='char', max_df=0.2, min_df=49,\n",
              "                                 ngram_range=(1, 3))),\n",
              "                ('xgboost',\n",
              "                 XGBClassifier(base_score=None, booster='gblinear',\n",
              "                               callbacks=None, colsample_bylevel=None,\n",
              "                               colsample_bynode=None, colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric='rmse',\n",
              "                               feature_types=None, gamma=None, gpu_id=N...\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.01,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=10, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=30,\n",
              "                               n_jobs=-1, num_parallel_tree=None,\n",
              "                               objective='multi:softprob', predictor=None, ...))])"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=49,\n",
              "                                 ngram_range=(1, 3))),\n",
              "                (&#x27;xgboost&#x27;,\n",
              "                 XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;,\n",
              "                               callbacks=None, colsample_bylevel=None,\n",
              "                               colsample_bynode=None, colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=&#x27;rmse&#x27;,\n",
              "                               feature_types=None, gamma=None, gpu_id=N...\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.01,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=10, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=30,\n",
              "                               n_jobs=-1, num_parallel_tree=None,\n",
              "                               objective=&#x27;multi:softprob&#x27;, predictor=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=49,\n",
              "                                 ngram_range=(1, 3))),\n",
              "                (&#x27;xgboost&#x27;,\n",
              "                 XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;,\n",
              "                               callbacks=None, colsample_bylevel=None,\n",
              "                               colsample_bynode=None, colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=&#x27;rmse&#x27;,\n",
              "                               feature_types=None, gamma=None, gpu_id=N...\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.01,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=10, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=30,\n",
              "                               n_jobs=-1, num_parallel_tree=None,\n",
              "                               objective=&#x27;multi:softprob&#x27;, predictor=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=49, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=30, n_jobs=-1, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the roc_auc score of the best params\n",
        "XG_pipline.set_params(**best_params2).score(X1,Y)"
      ],
      "metadata": {
        "id": "DIM8Sn-n6BYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85c31fb-45b9-456c-afd4-a06894da0bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:54:15] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8409833333333333"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test['id']\n",
        "submission['label'] = XG_pipline.predict_proba(test['text'])[:,1]\n",
        "submission.to_csv('XG.csv', index=False)"
      ],
      "metadata": {
        "id": "s2lurAUx8L6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost Classifier with Random Search when TfidfVectorizer --> character-level vectorizer. Get Score: 0.7554 on Kaggle \n",
        "we can improve it by trying to chance hyperparameter"
      ],
      "metadata": {
        "id": "1LYeP_MT8nuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Third trial"
      ],
      "metadata": {
        "id": "CZ90qlA8AEX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "building **(logistic regression Classifier with Random Search (validation))**\n"
      ],
      "metadata": {
        "id": "wn-mwPXM74IB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**this trial on train_lemma**"
      ],
      "metadata": {
        "id": "fJP83qdBGW_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting each text the input column to numerical values using TfidfVectorizer \n",
        "# training them using (logistic regression  Classifier).\n",
        "log_Pipeline = Pipeline(\n",
        "    steps=[\n",
        "        ('TF-IDF', TfidfVectorizer()),\n",
        "        ('lg', LogisticRegression(max_iter=10000,random_state=42,n_jobs=-1))]\n",
        ")\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "predefinedspilt3 = PredefinedSplit(split_index_lemmatized)\n",
        "\n",
        "# define parameter space to test\n",
        "\n",
        "params_lg={\n",
        "     # points to TfidfVectorizer->ngram_range \n",
        "    'TF-IDF__ngram_range':[(1, 2), (1, 3), (1,4), (1,5)],\n",
        "    # points to TfidfVectorizer->max_df \n",
        "    'TF-IDF__max_df': np.arange(0.2, 1.0),\n",
        "    # points to TfidfVectorizer->min_df \n",
        "    'TF-IDF__min_df': np.arange(5, 100),\n",
        "    # points to logistic regression->class_weight' \n",
        "    'lg__class_weight':['balanced',None],\n",
        "    # points to logistic regression->C' \n",
        "    'lg__C': [1.0,0.1,0.001,0.0001,0.005,1.5,2.0,3.5],\n",
        "    # points to logistic regression->fit_intercept' \n",
        "    'lg__fit_intercept':[False, True],\n",
        "}\n",
        "\n",
        "# it is quite slow so we do 4 for now\n",
        "#Using Random search with validation set\n",
        "#random search CV (may be good enough and even more generalizable)\n",
        "pipe_clf_lg = RandomizedSearchCV(\n",
        "log_Pipeline, params_lg, n_jobs=-1,cv=predefinedspilt3, scoring=\"roc_auc\", n_iter=3)\n",
        "\n",
        "# here we still use X1; but the Radom search model  will use our predefined split internally to determine which sample belongs to the validation set\n",
        "#Fit the model on train_lemma\n",
        "pipe_clf_lg.fit(X1, Y)"
      ],
      "metadata": {
        "id": "EeEuY2v0GchI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "89834ff3-c352-4faf-dc1b-80e0cb2cd1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0, -1])),\n",
              "                   estimator=Pipeline(steps=[('TF-IDF', TfidfVectorizer()),\n",
              "                                             ('lg',\n",
              "                                              LogisticRegression(max_iter=10000,\n",
              "                                                                 n_jobs=-1,\n",
              "                                                                 random_state=42))]),\n",
              "                   n_iter=3, n_jobs=-1,\n",
              "                   param_distributions={'TF-IDF__max_df': array([0.2]),\n",
              "                                        'TF-IDF__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25,...\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'TF-IDF__ngram_range': [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)],\n",
              "                                        'lg__C': [1.0, 0.1, 0.001, 0.0001,\n",
              "                                                  0.005, 1.5, 2.0, 3.5],\n",
              "                                        'lg__class_weight': ['balanced', None],\n",
              "                                        'lg__fit_intercept': [False, True]},\n",
              "                   scoring='roc_auc')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;, TfidfVectorizer()),\n",
              "                                             (&#x27;lg&#x27;,\n",
              "                                              LogisticRegression(max_iter=10000,\n",
              "                                                                 n_jobs=-1,\n",
              "                                                                 random_state=42))]),\n",
              "                   n_iter=3, n_jobs=-1,\n",
              "                   param_distributions={&#x27;TF-IDF__max_df&#x27;: array([0.2]),\n",
              "                                        &#x27;TF-IDF__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25,...\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)],\n",
              "                                        &#x27;lg__C&#x27;: [1.0, 0.1, 0.001, 0.0001,\n",
              "                                                  0.005, 1.5, 2.0, 3.5],\n",
              "                                        &#x27;lg__class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
              "                                        &#x27;lg__fit_intercept&#x27;: [False, True]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;, TfidfVectorizer()),\n",
              "                                             (&#x27;lg&#x27;,\n",
              "                                              LogisticRegression(max_iter=10000,\n",
              "                                                                 n_jobs=-1,\n",
              "                                                                 random_state=42))]),\n",
              "                   n_iter=3, n_jobs=-1,\n",
              "                   param_distributions={&#x27;TF-IDF__max_df&#x27;: array([0.2]),\n",
              "                                        &#x27;TF-IDF__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25,...\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)],\n",
              "                                        &#x27;lg__C&#x27;: [1.0, 0.1, 0.001, 0.0001,\n",
              "                                                  0.005, 1.5, 2.0, 3.5],\n",
              "                                        &#x27;lg__class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
              "                                        &#x27;lg__fit_intercept&#x27;: [False, True]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;lg&#x27;,\n",
              "                 LogisticRegression(max_iter=10000, n_jobs=-1,\n",
              "                                    random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best hyperparameters combinations and roc_auc score for TfidfVectorizer() logistic regression  Classifier\n",
        "best_params3 = pipe_clf_lg.best_params_\n",
        "print(best_params3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84646895-d305-430e-d461-6a418538f92c",
        "id": "GzohMg-ZCiiI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lg__fit_intercept': False, 'lg__class_weight': 'balanced', 'lg__C': 3.5, 'TF-IDF__ngram_range': (1, 2), 'TF-IDF__min_df': 15, 'TF-IDF__max_df': 0.2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the best hyperparameter combination for `TfidfVectorizer`() and use them with the model to search for best hyperparameters combination for the model.\n"
      ],
      "metadata": {
        "id": "DPDDmGfKCiiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this best hyperparameters for `TfidfVectorizer()`, we can search for optimal hyperparameters for logistic regression  Classifier becuase that will improve the classification results:\n",
        "\n"
      ],
      "metadata": {
        "id": "r94yQvorCiiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model with best param\n",
        "log_Pipeline.set_params(**best_params3).fit(X1, Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "3d965ac1-b217-45ae-c7e4-47d83c539a0c",
        "id": "58CO04N9Cyx4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('TF-IDF',\n",
              "                 TfidfVectorizer(max_df=0.2, min_df=15, ngram_range=(1, 2))),\n",
              "                ('lg',\n",
              "                 LogisticRegression(C=3.5, class_weight='balanced',\n",
              "                                    fit_intercept=False, max_iter=10000,\n",
              "                                    n_jobs=-1, random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(max_df=0.2, min_df=15, ngram_range=(1, 2))),\n",
              "                (&#x27;lg&#x27;,\n",
              "                 LogisticRegression(C=3.5, class_weight=&#x27;balanced&#x27;,\n",
              "                                    fit_intercept=False, max_iter=10000,\n",
              "                                    n_jobs=-1, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(max_df=0.2, min_df=15, ngram_range=(1, 2))),\n",
              "                (&#x27;lg&#x27;,\n",
              "                 LogisticRegression(C=3.5, class_weight=&#x27;balanced&#x27;,\n",
              "                                    fit_intercept=False, max_iter=10000,\n",
              "                                    n_jobs=-1, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.2, min_df=15, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=3.5, class_weight=&#x27;balanced&#x27;, fit_intercept=False,\n",
              "                   max_iter=10000, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the roc_auc score of the best params\n",
        "log_Pipeline.set_params(**best_params3).score(X1,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51f0755-b403-431c-89ee-07b445d59aee",
        "id": "RGDW6u1QCyx4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8576833333333334"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test['id']\n",
        "submission['label'] = log_Pipeline.predict_proba(test['text'])[:,1]\n",
        "submission.to_csv('log.csv', index=False)"
      ],
      "metadata": {
        "id": "ns5HdGItCyx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression with Random Search Get Score: 0.83602 on Kaggle \n",
        "we can improve it by trying to chance hyperparameter\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nNrMq7L7EiK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fourth trial**"
      ],
      "metadata": {
        "id": "jTVmOJdoEzGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "building **(logistic regression Classifier with Random Search (validation))**\n",
        "\n",
        "TfidfVectorizer (character-level)"
      ],
      "metadata": {
        "id": "j_BmWel0GZeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**this trial on train_stem**"
      ],
      "metadata": {
        "id": "OgnkFADgF8RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting each text the input column to numerical values using TfidfVectorizer \n",
        "# training them using (logistic regression  Classifier).\n",
        "log_Pipeline2 = Pipeline(\n",
        "    steps=[\n",
        "        ('TF-IDF', TfidfVectorizer(analyzer=\"char\", max_df=0.2, min_df=10, ngram_range=(1, 3), norm=\"l2\")),\n",
        "        ('lg', LogisticRegression(max_iter=10000,random_state=42,n_jobs=-1))]\n",
        ")\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "predefinedspilt4 = PredefinedSplit(split_index_stemmed)\n",
        "\n",
        "# define parameter space to test\n",
        "\n",
        "params_lg={\n",
        "     # points to TfidfVectorizer->ngram_range \n",
        "    'TF-IDF__ngram_range':[(1, 2), (1, 3), (1,4), (1,5)],\n",
        "    # points to TfidfVectorizer->max_df \n",
        "    'TF-IDF__max_df': np.arange(0.2, 1.0),\n",
        "    # points to TfidfVectorizer->min_df \n",
        "    'TF-IDF__min_df': np.arange(5, 100),\n",
        "    # points to logistic regression->class_weight' \n",
        "    'lg__class_weight':['balanced',None],\n",
        "    # points to logistic regression->C' \n",
        "    'lg__C': [1.0,0.1,0.001,0.0001,0.005,1.5,2.0,3.5],\n",
        "    # points to logistic regression->fit_intercept' \n",
        "    'lg__fit_intercept':[False, True],\n",
        "}\n",
        "\n",
        "# it is quite slow so we do 4 for now\n",
        "#Using Random search with validation set\n",
        "#random search CV (may be good enough and even more generalizable)\n",
        "pipe_clf_lg = RandomizedSearchCV(\n",
        "log_Pipeline2, params_lg, n_jobs=-1,cv=predefinedspilt4, scoring=\"roc_auc\", n_iter=3)\n",
        "\n",
        "# here we still use X2; but the Radom search model  will use our predefined split internally to determine which sample belongs to the validation set\n",
        "#Fit the model on train_stem\n",
        "pipe_clf_lg.fit(X2, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "be730e95-057e-490b-de6c-7f77cd3e1117",
        "id": "FBUSwpvJGtGY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0, -1])),\n",
              "                   estimator=Pipeline(steps=[('TF-IDF',\n",
              "                                              TfidfVectorizer(analyzer='char',\n",
              "                                                              max_df=0.2,\n",
              "                                                              min_df=10,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           3))),\n",
              "                                             ('lg',\n",
              "                                              LogisticRegression(max_iter=10000,\n",
              "                                                                 n_jobs=-1,\n",
              "                                                                 random_state=42))]),\n",
              "                   n_iter=3, n_jobs=-1,\n",
              "                   param_distributions={'TF-IDF__analyzer': ['char'],\n",
              "                                        'TF-IDF__max_df': array([0.2]),...\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'TF-IDF__ngram_range': [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)],\n",
              "                                        'lg__C': [1.0, 0.1, 0.001, 0.0001,\n",
              "                                                  0.005, 1.5, 2.0, 3.5],\n",
              "                                        'lg__class_weight': ['balanced', None],\n",
              "                                        'lg__fit_intercept': [False, True]},\n",
              "                   scoring='roc_auc')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                                              TfidfVectorizer(analyzer=&#x27;char&#x27;,\n",
              "                                                              max_df=0.2,\n",
              "                                                              min_df=10,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           3))),\n",
              "                                             (&#x27;lg&#x27;,\n",
              "                                              LogisticRegression(max_iter=10000,\n",
              "                                                                 n_jobs=-1,\n",
              "                                                                 random_state=42))]),\n",
              "                   n_iter=3, n_jobs=-1,\n",
              "                   param_distributions={&#x27;TF-IDF__analyzer&#x27;: [&#x27;char&#x27;],\n",
              "                                        &#x27;TF-IDF__max_df&#x27;: array([0.2]),...\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)],\n",
              "                                        &#x27;lg__C&#x27;: [1.0, 0.1, 0.001, 0.0001,\n",
              "                                                  0.005, 1.5, 2.0, 3.5],\n",
              "                                        &#x27;lg__class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
              "                                        &#x27;lg__fit_intercept&#x27;: [False, True]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                                              TfidfVectorizer(analyzer=&#x27;char&#x27;,\n",
              "                                                              max_df=0.2,\n",
              "                                                              min_df=10,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           3))),\n",
              "                                             (&#x27;lg&#x27;,\n",
              "                                              LogisticRegression(max_iter=10000,\n",
              "                                                                 n_jobs=-1,\n",
              "                                                                 random_state=42))]),\n",
              "                   n_iter=3, n_jobs=-1,\n",
              "                   param_distributions={&#x27;TF-IDF__analyzer&#x27;: [&#x27;char&#x27;],\n",
              "                                        &#x27;TF-IDF__max_df&#x27;: array([0.2]),...\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)],\n",
              "                                        &#x27;lg__C&#x27;: [1.0, 0.1, 0.001, 0.0001,\n",
              "                                                  0.005, 1.5, 2.0, 3.5],\n",
              "                                        &#x27;lg__class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
              "                                        &#x27;lg__fit_intercept&#x27;: [False, True]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=10,\n",
              "                                 ngram_range=(1, 3))),\n",
              "                (&#x27;lg&#x27;,\n",
              "                 LogisticRegression(max_iter=10000, n_jobs=-1,\n",
              "                                    random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=10, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best hyperparameters combinations and roc_auc score for TfidfVectorizer() logistic regression  Classifier\n",
        "best_params4 = pipe_clf_lg.best_params_\n",
        "print(best_params4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafdcc30-460a-4694-ea6a-8ef8a008dba7",
        "id": "YHIWUKmlGtGZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lg__fit_intercept': True, 'lg__class_weight': 'balanced', 'lg__C': 3.5, 'TF-IDF__ngram_range': (1, 2), 'TF-IDF__min_df': 43, 'TF-IDF__max_df': 0.2, 'TF-IDF__analyzer': 'char'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the best hyperparameter combination for `TfidfVectorizer`() and use them with the model to search for best hyperparameters combination for the model.\n"
      ],
      "metadata": {
        "id": "1vVmihJmGtGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this best hyperparameters for `TfidfVectorizer()`, we can search for optimal hyperparameters for logistic regression  Classifier becuase that will improve the classification results:\n",
        "\n"
      ],
      "metadata": {
        "id": "2DN0Qw24GtGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model with best param\n",
        "log_Pipeline.set_params(**best_params4).fit(X2, Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "51cc0f19-c36c-4c39-d928-567c83ccb6f2",
        "id": "bkOyPE4eGtGZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('TF-IDF',\n",
              "                 TfidfVectorizer(analyzer='char', max_df=0.2, min_df=43,\n",
              "                                 ngram_range=(1, 2))),\n",
              "                ('lg',\n",
              "                 LogisticRegression(C=3.5, class_weight='balanced',\n",
              "                                    max_iter=10000, n_jobs=-1,\n",
              "                                    random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=43,\n",
              "                                 ngram_range=(1, 2))),\n",
              "                (&#x27;lg&#x27;,\n",
              "                 LogisticRegression(C=3.5, class_weight=&#x27;balanced&#x27;,\n",
              "                                    max_iter=10000, n_jobs=-1,\n",
              "                                    random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=43,\n",
              "                                 ngram_range=(1, 2))),\n",
              "                (&#x27;lg&#x27;,\n",
              "                 LogisticRegression(C=3.5, class_weight=&#x27;balanced&#x27;,\n",
              "                                    max_iter=10000, n_jobs=-1,\n",
              "                                    random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=43, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=3.5, class_weight=&#x27;balanced&#x27;, max_iter=10000, n_jobs=-1,\n",
              "                   random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the roc_auc score of the best params\n",
        "log_Pipeline.set_params(**best_params4).score(X2,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18760613-84c3-4ed6-df05-dcf1749cac07",
        "id": "RHc_O-USGtGZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.80435"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test['id']\n",
        "submission['label'] = log_Pipeline.predict_proba(test['text'])[:,1]\n",
        "submission.to_csv('log2.csv', index=False)"
      ],
      "metadata": {
        "id": "w4DLzOnAGtGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this model on train_stem with TfidfVectorizer (character-level) getScore: `0.74112` on kaggle \n",
        "\n",
        "SO, I noticed that Lemmatization has higher accuracy than stemming.\n",
        "(Lemmatization is preferred for context analysis, whereas stemming is recommended when the context is not important.)\n"
      ],
      "metadata": {
        "id": "_OazArzie_Mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fifth trail"
      ],
      "metadata": {
        "id": "SZScGgA5f2ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  building **(MLP Classifier with Random Search (validation))**\n",
        "\n",
        "*  TfidfVectorizer (character-level)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V148cGuvibkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**this trial on train_Lemma**"
      ],
      "metadata": {
        "id": "8F8T8zfTibkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting each text the input column to numerical values using TfidfVectorizer \n",
        "# training them using (logistic regression  Classifier).\n",
        "MLP_Pipeline = Pipeline(\n",
        "    steps=[\n",
        "        ('TF-IDF', TfidfVectorizer()),\n",
        "        ('MLP', MLPClassifier(random_state=1,solver=\"adam\",hidden_layer_sizes=(12, 12, 12),activation=\"relu\",early_stopping=True,n_iter_no_change=1))\n",
        "        ]\n",
        ")\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "predefinedspilt5 = PredefinedSplit(split_index_lemmatized)\n",
        "\n",
        "# define parameter space to test\n",
        "\n",
        "params0={\n",
        "    # points to TfidfVectorizer->ngram_range \n",
        "    'TF-IDF__ngram_range': [(1, 2), (1, 3), (1,4), (1,5)],\n",
        "    # points to TfidfVectorizer->analyzer \n",
        "    'TF-IDF__analyzer':['char'],\n",
        "    # points to TfidfVectorizer->min_df \n",
        "    'TF-IDF__min_df':np.arange(5, 100),\n",
        "    # points to TfidfVectorizer->max_df \n",
        "    'TF-IDF__max_df':np.arange(0.2, 1.0),\n",
        "}\n",
        "\n",
        "# it is quite slow so we do 4 for now\n",
        "#Using Random search with validation set\n",
        "#random search CV (may be good enough and even more generalizable)\n",
        "pipe_clf_MLP = RandomizedSearchCV(\n",
        "MLP_Pipeline, params0, n_jobs=-1,cv=predefinedspilt5, scoring=\"roc_auc\", n_iter=3)\n",
        "\n",
        "# here we still use X1; but the Radom search model  will use our predefined split internally to determine which sample belongs to the validation set\n",
        "#Fit the model on train_lemma\n",
        "pipe_clf_MLP.fit(X1, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "47876453-f484-4ead-c879-bed1826c0f3c",
        "id": "dXT-rnuBibkN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[('TF-IDF', TfidfVectorizer()),\n",
              "                                             ('MLP',\n",
              "                                              MLPClassifier(early_stopping=True,\n",
              "                                                            hidden_layer_sizes=(12,\n",
              "                                                                                12,\n",
              "                                                                                12),\n",
              "                                                            n_iter_no_change=1,\n",
              "                                                            random_state=1))]),\n",
              "                   n_iter=3, n_jobs=-1,\n",
              "                   param_distributions={'TF-IDF__analyzer': ['char'],\n",
              "                                        'TF-IDF__max_df': array([0.2]),\n",
              "                                        'TF-IDF__min_df...[ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'TF-IDF__ngram_range': [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)]},\n",
              "                   scoring='roc_auc')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;, TfidfVectorizer()),\n",
              "                                             (&#x27;MLP&#x27;,\n",
              "                                              MLPClassifier(early_stopping=True,\n",
              "                                                            hidden_layer_sizes=(12,\n",
              "                                                                                12,\n",
              "                                                                                12),\n",
              "                                                            n_iter_no_change=1,\n",
              "                                                            random_state=1))]),\n",
              "                   n_iter=3, n_jobs=-1,\n",
              "                   param_distributions={&#x27;TF-IDF__analyzer&#x27;: [&#x27;char&#x27;],\n",
              "                                        &#x27;TF-IDF__max_df&#x27;: array([0.2]),\n",
              "                                        &#x27;TF-IDF__min_df...[ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;, TfidfVectorizer()),\n",
              "                                             (&#x27;MLP&#x27;,\n",
              "                                              MLPClassifier(early_stopping=True,\n",
              "                                                            hidden_layer_sizes=(12,\n",
              "                                                                                12,\n",
              "                                                                                12),\n",
              "                                                            n_iter_no_change=1,\n",
              "                                                            random_state=1))]),\n",
              "                   n_iter=3, n_jobs=-1,\n",
              "                   param_distributions={&#x27;TF-IDF__analyzer&#x27;: [&#x27;char&#x27;],\n",
              "                                        &#x27;TF-IDF__max_df&#x27;: array([0.2]),\n",
              "                                        &#x27;TF-IDF__min_df...[ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3),\n",
              "                                                                (1, 4),\n",
              "                                                                (1, 5)]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;MLP&#x27;,\n",
              "                 MLPClassifier(early_stopping=True,\n",
              "                               hidden_layer_sizes=(12, 12, 12),\n",
              "                               n_iter_no_change=1, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 12, 12),\n",
              "              n_iter_no_change=1, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best hyperparameters combinations and roc_auc score for TfidfVectorizer() logistic regression  Classifier\n",
        "best_params5 = pipe_clf_MLP.best_params_\n",
        "print(best_params5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b314ee9-d605-4dc5-bdaa-59319efb0685",
        "id": "e42uWowribkO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TF-IDF__ngram_range': (1, 4), 'TF-IDF__min_df': 76, 'TF-IDF__max_df': 0.2, 'TF-IDF__analyzer': 'char'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the best hyperparameter combination for `TfidfVectorizer`() and use them with the model to search for best hyperparameters combination for the model.\n"
      ],
      "metadata": {
        "id": "ZHdizY7YibkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this best hyperparameters for `TfidfVectorizer()`, we can search for optimal hyperparameters for MLP Classifier becuase that will improve the classification results:\n",
        "\n"
      ],
      "metadata": {
        "id": "jTm0YZRSibkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model with best param\n",
        "MLP_Pipeline.set_params(**best_params5).fit(X1, Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "1afe3271-0fd9-4542-f3f2-6b8a8a742421",
        "id": "JJvzvdU8ibkO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('TF-IDF',\n",
              "                 TfidfVectorizer(analyzer='char', max_df=0.2, min_df=76,\n",
              "                                 ngram_range=(1, 4))),\n",
              "                ('MLP',\n",
              "                 MLPClassifier(early_stopping=True,\n",
              "                               hidden_layer_sizes=(12, 12, 12),\n",
              "                               n_iter_no_change=1, random_state=1))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=76,\n",
              "                                 ngram_range=(1, 4))),\n",
              "                (&#x27;MLP&#x27;,\n",
              "                 MLPClassifier(early_stopping=True,\n",
              "                               hidden_layer_sizes=(12, 12, 12),\n",
              "                               n_iter_no_change=1, random_state=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=76,\n",
              "                                 ngram_range=(1, 4))),\n",
              "                (&#x27;MLP&#x27;,\n",
              "                 MLPClassifier(early_stopping=True,\n",
              "                               hidden_layer_sizes=(12, 12, 12),\n",
              "                               n_iter_no_change=1, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.2, min_df=76, ngram_range=(1, 4))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 12, 12),\n",
              "              n_iter_no_change=1, random_state=1)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the roc_auc score of the best params\n",
        "MLP_Pipeline.set_params(**best_params5).score(X1,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d926782e-1614-4415-9459-4158790ba7a6",
        "id": "sUMXe6iuibkO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89655"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test['id']\n",
        "submission['label'] = MLP_Pipeline.predict_proba(test['text'])[:,1]\n",
        "submission.to_csv('MLP.csv', index=False)"
      ],
      "metadata": {
        "id": "wr24lmBYibkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP model on train_lemma  get Score: `0.8164` on kaggle ,we can improve it by trying to chance hyperparameter\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WZOTAflfmTt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VI trail"
      ],
      "metadata": {
        "id": "2ipNU6P3GCQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   building **(XGBoost Classifier with Random Search (validation))**\n",
        "\n",
        "*   TfidfVectorizer --> word-level vectorizer.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zaybHZtmGfTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**this trial on train_lemma**\n",
        "\n"
      ],
      "metadata": {
        "id": "TWau6DVlGfTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting each text the input column to numerical values using TfidfVectorizer \n",
        "# training them using XGBoost Classifier.\n",
        "XG_pipline2 = Pipeline(\n",
        "    steps=[\n",
        "        ('TF-IDF', TfidfVectorizer(analyzer=\"word\", max_df=0.4, min_df=10, ngram_range=(1, 2))),\n",
        "        ('xgboost', XGBClassifier(eval_metric='rmse',max_depth=5,n_estimators=200,use_label_encoder=False))]\n",
        ")\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "predefinedspilt6 = PredefinedSplit(split_index_lemmatized)\n",
        "\n",
        "# define parameter space to test\n",
        "\n",
        "params_XG2={\n",
        "    # points to TfidfVectorizer->ngram_range \n",
        "    'TF-IDF__ngram_range':[(1,2),(1,3)],\n",
        "    # points to TfidfVectorizer->Max_df \n",
        "    'TF-IDF__max_df': np.arange(0.3, 0.8),\n",
        "    # points to TfidfVectorizer->Min_df \n",
        "    'TF-IDF__min_df': np.arange(5, 100),\n",
        "    # points to xgboost->n_estimators' \n",
        "    'xgboost__n_estimators': [20, 30, 40], \n",
        "    # points to xgboost->max_depth' \n",
        "    'xgboost__max_depth':[10, 20, 30],\n",
        "    # points to xgboost->booster' \n",
        "    'xgboost__booster':['gbtree','gblinear', 'dart'],\n",
        "    # points to xgboost->learning_rate' \n",
        "    'xgboost__learning_rate':[1.0, 0.1,0.01,0.0001, 1.5],  \n",
        "}\n",
        "\n",
        "# it is quite slow so we do 4 for now\n",
        "#Using Random search with validation set\n",
        "#random search CV (may be good enough and even more generalizable)\n",
        "pipe_clf_XG2 = RandomizedSearchCV(\n",
        "XG_pipline2, params_XG2, cv=predefinedspilt6, n_jobs=-1, scoring=\"roc_auc\", n_iter=3)\n",
        "\n",
        "# here we still use X1; but the Radom search model  will use our predefined split internally to determine which sample belongs to the validation set\n",
        "#Fit the model on train_lemma\n",
        "pipe_clf_XG2.fit(X1, Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "61d8b71d-ee66-4d3d-907b-26289ac1cd91",
        "id": "Kk0WEA_bHM0t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
            "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
            "/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
            "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:37:51] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[('TF-IDF',\n",
              "                                              TfidfVectorizer(max_df=0.4,\n",
              "                                                              min_df=10,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           2))),\n",
              "                                             ('xgboost',\n",
              "                                              XGBClassifier(base_score=None,\n",
              "                                                            booster=None,\n",
              "                                                            callbacks=None,\n",
              "                                                            colsample_bylevel=None,\n",
              "                                                            colsample_bynode=None,\n",
              "                                                            colsample_bytree=None,\n",
              "                                                            early_stopping_rounds=None,\n",
              "                                                            enable_categorical=Fa...\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'TF-IDF__ngram_range': [(1, 2), (1, 3)],\n",
              "                                        'xgboost__booster': ['gbtree',\n",
              "                                                             'gblinear',\n",
              "                                                             'dart'],\n",
              "                                        'xgboost__learning_rate': [1.0, 0.1,\n",
              "                                                                   0.01, 0.0001,\n",
              "                                                                   1.5],\n",
              "                                        'xgboost__max_depth': [10, 20, 30],\n",
              "                                        'xgboost__n_estimators': [20, 30, 40]},\n",
              "                   scoring='roc_auc')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                                              TfidfVectorizer(max_df=0.4,\n",
              "                                                              min_df=10,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           2))),\n",
              "                                             (&#x27;xgboost&#x27;,\n",
              "                                              XGBClassifier(base_score=None,\n",
              "                                                            booster=None,\n",
              "                                                            callbacks=None,\n",
              "                                                            colsample_bylevel=None,\n",
              "                                                            colsample_bynode=None,\n",
              "                                                            colsample_bytree=None,\n",
              "                                                            early_stopping_rounds=None,\n",
              "                                                            enable_categorical=Fa...\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3)],\n",
              "                                        &#x27;xgboost__booster&#x27;: [&#x27;gbtree&#x27;,\n",
              "                                                             &#x27;gblinear&#x27;,\n",
              "                                                             &#x27;dart&#x27;],\n",
              "                                        &#x27;xgboost__learning_rate&#x27;: [1.0, 0.1,\n",
              "                                                                   0.01, 0.0001,\n",
              "                                                                   1.5],\n",
              "                                        &#x27;xgboost__max_depth&#x27;: [10, 20, 30],\n",
              "                                        &#x27;xgboost__n_estimators&#x27;: [20, 30, 40]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0, -1, ..., -1, -1])),\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                                              TfidfVectorizer(max_df=0.4,\n",
              "                                                              min_df=10,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           2))),\n",
              "                                             (&#x27;xgboost&#x27;,\n",
              "                                              XGBClassifier(base_score=None,\n",
              "                                                            booster=None,\n",
              "                                                            callbacks=None,\n",
              "                                                            colsample_bylevel=None,\n",
              "                                                            colsample_bynode=None,\n",
              "                                                            colsample_bytree=None,\n",
              "                                                            early_stopping_rounds=None,\n",
              "                                                            enable_categorical=Fa...\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2), (1, 3)],\n",
              "                                        &#x27;xgboost__booster&#x27;: [&#x27;gbtree&#x27;,\n",
              "                                                             &#x27;gblinear&#x27;,\n",
              "                                                             &#x27;dart&#x27;],\n",
              "                                        &#x27;xgboost__learning_rate&#x27;: [1.0, 0.1,\n",
              "                                                                   0.01, 0.0001,\n",
              "                                                                   1.5],\n",
              "                                        &#x27;xgboost__max_depth&#x27;: [10, 20, 30],\n",
              "                                        &#x27;xgboost__n_estimators&#x27;: [20, 30, 40]},\n",
              "                   scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(max_df=0.4, min_df=10, ngram_range=(1, 2))),\n",
              "                (&#x27;xgboost&#x27;,\n",
              "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=&#x27;rmse&#x27;,\n",
              "                               feature_types=None, gamma=None, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=None,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=5, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=200,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.4, min_df=10, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best hyperparameters combinations and roc_auc score for TfidfVectorizer() XGBoost Classifier\n",
        "best_params6 = pipe_clf_XG2.best_params_\n",
        "print(best_params6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHSnuYBvHM0t",
        "outputId": "6c98ede1-c64a-4ff6-cc7c-c35941d74b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'xgboost__n_estimators': 20, 'xgboost__max_depth': 20, 'xgboost__learning_rate': 1.0, 'xgboost__booster': 'gblinear', 'TF-IDF__ngram_range': (1, 3), 'TF-IDF__min_df': 65, 'TF-IDF__max_df': 0.3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the best hyperparameter combination for `TfidfVectorizer`() and use them with the model to search for best hyperparameters combination for the model.\n"
      ],
      "metadata": {
        "id": "TX2J8IhiHM0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this best hyperparameters for `TfidfVectorizer()`, we can search for optimal hyperparameters for XGBoost Classifier becuase that will improve the classification results:\n",
        "\n"
      ],
      "metadata": {
        "id": "qPRnpER-HM0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model with best param\n",
        "XG_pipline2.set_params(**best_params6).fit(X1, Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "fZypTFBSHM0u",
        "outputId": "41284b91-cb51-4331-ea26-cedab2feb486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:38:20] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('TF-IDF',\n",
              "                 TfidfVectorizer(max_df=0.3, min_df=65, ngram_range=(1, 3))),\n",
              "                ('xgboost',\n",
              "                 XGBClassifier(base_score=None, booster='gblinear',\n",
              "                               callbacks=None, colsample_bylevel=None,\n",
              "                               colsample_bynode=None, colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric='rmse',\n",
              "                               feature_types=None, gamma=None, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=1.0,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=20, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=20,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               objective='multi:softprob', predictor=None, ...))])"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(max_df=0.3, min_df=65, ngram_range=(1, 3))),\n",
              "                (&#x27;xgboost&#x27;,\n",
              "                 XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;,\n",
              "                               callbacks=None, colsample_bylevel=None,\n",
              "                               colsample_bynode=None, colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=&#x27;rmse&#x27;,\n",
              "                               feature_types=None, gamma=None, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=1.0,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=20, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=20,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               objective=&#x27;multi:softprob&#x27;, predictor=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(max_df=0.3, min_df=65, ngram_range=(1, 3))),\n",
              "                (&#x27;xgboost&#x27;,\n",
              "                 XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;,\n",
              "                               callbacks=None, colsample_bylevel=None,\n",
              "                               colsample_bynode=None, colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=&#x27;rmse&#x27;,\n",
              "                               feature_types=None, gamma=None, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=1.0,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=20, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=20,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               objective=&#x27;multi:softprob&#x27;, predictor=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.3, min_df=65, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=1.0, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=20, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=20, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the roc_auc score of the best params\n",
        "XG_pipline2.set_params(**best_params6).score(X1,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Go8orNHM0u",
        "outputId": "5e445d2a-d968-4912-9cf6-a4fbbe70e7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:38:25] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8091333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test['id']\n",
        "submission['label'] = XG_pipline2.predict_proba(test['text'])[:,1]\n",
        "submission.to_csv('XG2.csv', index=False)"
      ],
      "metadata": {
        "id": "KT8KaNbUHM0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost Classifier with Random Search when TfidfVectorizer --> word-level vectorizer. Get Score: 0.0.8164 on Kaggle \n",
        "we can improve it by trying to chance hyperparameter"
      ],
      "metadata": {
        "id": "KdmMh7G6JzkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VII trial \n"
      ],
      "metadata": {
        "id": "AO68DmFYtxnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*    TfidfVectorizer by default `word-level vectorizer.`\n",
        "*    building  Random Forest with Random Search (Cross-validation)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6hhXIJb9txnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's try **Cross-validation** is usually the preferred method because it gives your model the opportunity to train on multiple train-test splits."
      ],
      "metadata": {
        "id": "qYJZvodQw5HA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting each text the input column to numerical values using TfidfVectorizer \n",
        "# training them using Random Forest classifier.\n",
        "\n",
        "RF_pipline2 = Pipeline(\n",
        "    steps=[\n",
        "        ('TF-IDF', TfidfVectorizer()),\n",
        "        ('RandomForest', RandomForestClassifier())]\n",
        ")\n",
        "\n",
        "# define parameter space to test\n",
        "\n",
        "params2={\n",
        "    # points to TfidfVectorizer->ngram_range \n",
        "    'TF-IDF__ngram_range':[(1,2),(1,3)],\n",
        "    # points to TfidfVectorizer->Max_df \n",
        "    'TF-IDF__max_df': np.arange(0.3, 0.8),\n",
        "    # points to TfidfVectorizer->Min_df \n",
        "    'TF-IDF__min_df': np.arange(5, 100),\n",
        "}\n",
        "\n",
        "# it is quite slow so we do 4 for now\n",
        "\n",
        "#random search CV (may be good enough and even more generalizable)\n",
        "#using random search\n",
        "# cv=2 means two-fold cross-validation\n",
        "# n_jobs means the cucurrent number of jobs\n",
        "# (on colab since we only have two cpu cores, we set it to 2)\n",
        "pipe_clf_RF2 = RandomizedSearchCV(\n",
        "    RF_pipline2, params2,cv=2, verbose=1, n_jobs=2, \n",
        "    # number of random trials\n",
        "    n_iter=10,\n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X1; but the Radom search model  will use our predefined split internally to determine which sample belongs to the validation set\n",
        "\n",
        "#Fit the model on train_lemma\n",
        "pipe_clf_RF2.fit(X1, Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3wvkcBI7txnQ",
        "outputId": "cb738630-13d0-4d4f-fee9-4bae286ff46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=2,\n",
              "                   estimator=Pipeline(steps=[('TF-IDF', TfidfVectorizer()),\n",
              "                                             ('RandomForest',\n",
              "                                              RandomForestClassifier())]),\n",
              "                   n_jobs=2,\n",
              "                   param_distributions={'TF-IDF__max_df': array([0.3]),\n",
              "                                        'TF-IDF__min_df': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'TF-IDF__ngram_range': [(1, 2),\n",
              "                                                                (1, 3)]},\n",
              "                   scoring='roc_auc', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2,\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;, TfidfVectorizer()),\n",
              "                                             (&#x27;RandomForest&#x27;,\n",
              "                                              RandomForestClassifier())]),\n",
              "                   n_jobs=2,\n",
              "                   param_distributions={&#x27;TF-IDF__max_df&#x27;: array([0.3]),\n",
              "                                        &#x27;TF-IDF__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2),\n",
              "                                                                (1, 3)]},\n",
              "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2,\n",
              "                   estimator=Pipeline(steps=[(&#x27;TF-IDF&#x27;, TfidfVectorizer()),\n",
              "                                             (&#x27;RandomForest&#x27;,\n",
              "                                              RandomForestClassifier())]),\n",
              "                   n_jobs=2,\n",
              "                   param_distributions={&#x27;TF-IDF__max_df&#x27;: array([0.3]),\n",
              "                                        &#x27;TF-IDF__min_df&#x27;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
              "       39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
              "       90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        &#x27;TF-IDF__ngram_range&#x27;: [(1, 2),\n",
              "                                                                (1, 3)]},\n",
              "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;RandomForest&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best hyperparameters combinations and roc_auc score for TfidfVectorizer() Random Forest classifier\n",
        "\n",
        "best_params7 = pipe_clf_RF2.best_params_\n",
        "print(best_params7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI_XTnGJtxnQ",
        "outputId": "b2ae4bd9-5a02-4125-e972-79b0427b71e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TF-IDF__ngram_range': (1, 3), 'TF-IDF__min_df': 79, 'TF-IDF__max_df': 0.3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the best hyperparameter combination for `TfidfVectorizer`() and use them with the model to search for best hyperparameters combination for the model.\n"
      ],
      "metadata": {
        "id": "FmZv6JaetxnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this best hyperparameters for `TfidfVectorizer()`, we can search for optimal hyperparameters for the Random Forest classifier becuase that will improve the classification results:\n",
        "\n"
      ],
      "metadata": {
        "id": "4DQzz1FotxnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model with best param\n",
        "\n",
        "RF_pipline2.set_params(**best_params7).fit(X1, Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "gCCKU4wBtxnQ",
        "outputId": "0b0059a0-8056-4c16-e3e3-7b5e4a545bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('TF-IDF',\n",
              "                 TfidfVectorizer(max_df=0.3, min_df=79, ngram_range=(1, 3))),\n",
              "                ('RandomForest', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(max_df=0.3, min_df=79, ngram_range=(1, 3))),\n",
              "                (&#x27;RandomForest&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-IDF&#x27;,\n",
              "                 TfidfVectorizer(max_df=0.3, min_df=79, ngram_range=(1, 3))),\n",
              "                (&#x27;RandomForest&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.3, min_df=79, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the roc_auc score of the best params\n",
        "RF_pipline2.set_params(**best_params7).score(X1,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPaNe-qBtxnQ",
        "outputId": "c41d9d40-7f22-4bb6-d929-eb6d4f2b982d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9993833333333333"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test['id']\n",
        "submission['label'] = RF_pipline2.predict_proba(test['text'])[:,1]\n",
        "submission.to_csv('Randomforest2.csv', index=False)"
      ],
      "metadata": {
        "id": "nkL2A_pgtxnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest with Random Search (Cross-validation) Get the best Score on Kaggle (0.81898)\n",
        "we can improve it by trying to chance hyperparameter"
      ],
      "metadata": {
        "id": "cQG9R8pPtxnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion ‚≠ê\n",
        "\n",
        "*   I noticed that the TfidfVectorizer --> `word-level` vectorizer get score better than TfidfVectorizer --> `character-level` vectorizer.\n",
        "*  I noticed that Lemmatization has higher accuracy than stemming.\n",
        "(Lemmatization is preferred for context analysis, whereas stemming is recommended when the context is not important.)\n",
        "\n",
        "*   I used the Random Search because it's faster than grid search and reduces unnecessary computation.\n",
        "\n",
        "*   The best score on Kaggle **`(0.85350)`** when, I used **Random Forest model with Random Search (Vaildation).**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IxHoyDRNKJoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úîÔ∏è Answer the questions"
      ],
      "metadata": {
        "id": "WiOA5ST3Ozd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üåà What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?**\n",
        "\n",
        "\n",
        "\n",
        "*  A character n-Gram is defined as a series of characters of length n.\n",
        "*  A Word n-grams is is a contiguous series of n words from a given sample of text or speech.\n",
        "*   word n-gram is suffer more from the OOV issue.\n",
        "\n",
        "\n",
        "**üåà What is the difference between stop word removal and stemming? Are these techniques language-dependent?**\n",
        "\n",
        "\n",
        "\n",
        "*   The \"stemming\" is turning a word into a root word by removing the phrase prefix , While the \"stopwords removal\" is removed words that often appear and do not have any meaning.\n",
        "\n",
        "*  Stop word elimination and stemming are commonly used method in indexing. Stop words are high frequency words that have little semantic weight and are thus unlikely to help the retrieval process. \n",
        "\n",
        "*   both are language dependant stop words in English not like in German and vice versa also the grammars in English not like in the German language.\n",
        "\n",
        "\n",
        "\n",
        "**üåà Is tokenization techniques language dependent? Why?**\n",
        "\n",
        "No,because the tokenization is a way of separating a piece of text into smaller units called tokens. Different word-level tokens are created depending on the delimiters, not the language.\n",
        "\n",
        "\n",
        "**üåà What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?**\n",
        "\n",
        "\n",
        "*   CountVectorizer simply counts the number of times a word appears in a document (using a bag-of-words approach), while TF-IDF Vectorizer takes into account not only how many times a word appears in a document but also how important that word is to the whole corpus.\n",
        "*  It wouldn't be feasiable and it would be np-complete problem.\n",
        "*  we can select them by using some of search method techniques like (Grid search, random search).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pFcgWagyPAXX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJjO8YXjH7WJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}